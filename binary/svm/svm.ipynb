{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0743398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1560e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (59611, 24)\n",
      "Test shape: (14900, 23)\n",
      "\n",
      "Number of duplicate rows in train: 13\n",
      "Duplicates removed. New shape: (59598, 24)\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "train = pd.read_csv(\"../train.csv\")\n",
    "test = pd.read_csv(\"../test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "\n",
    "dup_count = train.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows in train: {dup_count}\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicates removed. New shape:\", train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebba46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING \n",
    "log_transform_cols = [\n",
    "    'monthly_revenue_generated', 'funding_rounds_led',\n",
    "    'num_dependents', 'years_with_startup'\n",
    "]\n",
    "\n",
    "def feature_engineer(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    if 'years_with_startup' in df.columns and 'years_since_founding' in df.columns:\n",
    "        df['experience_ratio'] = df['years_with_startup'] / (df['years_since_founding'] + np.finfo(float).eps)\n",
    "    \n",
    "    if 'founder_age' in df.columns and 'years_with_startup' in df.columns:\n",
    "        df['founder_join_age'] = df['founder_age'] - df['years_with_startup']\n",
    "    \n",
    "    if 'monthly_revenue_generated' in df.columns and 'funding_rounds_led' in df.columns:\n",
    "        df['revenue_per_round'] = df['monthly_revenue_generated'] / (df['funding_rounds_led'] + 1)\n",
    "\n",
    "    for col in log_transform_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'log_{col}'] = np.log1p(df[col])\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_fe = feature_engineer(train.drop(columns=['founder_id']))\n",
    "test_fe = feature_engineer(test.drop(columns=['founder_id']))\n",
    "\n",
    "X = train_fe.drop(columns=['retention_status'])\n",
    "y = train_fe['retention_status'].map({'Stayed': 1, 'Left': 0})\n",
    "X_test_final = test_fe\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d9fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN DEFINITIONS \n",
    "numerical_cols = [\n",
    "    'years_since_founding', 'founder_age', 'distance_from_investor_hub',\n",
    "    'experience_ratio', 'founder_join_age', 'revenue_per_round',\n",
    "    'log_monthly_revenue_generated', 'log_funding_rounds_led',\n",
    "    'log_num_dependents', 'log_years_with_startup'\n",
    "]\n",
    "\n",
    "binary_cols = ['working_overtime', 'remote_operations', 'leadership_scope', 'innovation_support']\n",
    "\n",
    "ordinal_cols = {\n",
    "    'work_life_balance_rating': ['Poor', 'Fair', 'Good', 'Excellent'],\n",
    "    'venture_satisfaction': ['Low', 'Medium', 'High', 'Very High'],\n",
    "    'startup_performance_rating': ['Low', 'Below Average', 'Average', 'High'],\n",
    "    'startup_reputation': ['Poor', 'Fair', 'Good', 'Excellent'],\n",
    "    'founder_visibility': ['Low', 'Medium', 'High', 'Very High'],\n",
    "    'startup_stage': ['Entry', 'Mid', 'Senior'],\n",
    "    'team_size_category': ['Small', 'Medium', 'Large']\n",
    "}\n",
    "\n",
    "ordinal_feature_names = list(ordinal_cols.keys())\n",
    "ordinal_categories = list(ordinal_cols.values())\n",
    "\n",
    "nominal_cols = ['founder_gender', 'founder_role', 'education_background', 'personal_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5d7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PREPROCESSING\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('mapper', OrdinalEncoder(categories=[['No', 'Yes']] * len(binary_cols),\n",
    "                              handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(categories=ordinal_categories,\n",
    "                                       handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_cols),\n",
    "        ('bin', binary_pipeline, binary_cols),\n",
    "        ('ord', ordinal_pipeline, ordinal_feature_names),\n",
    "        ('nom', nominal_pipeline, nominal_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e823c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM DATA \n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_test_val)\n",
    "X_test_processed = preprocessor.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70506a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SVM CONFIG \n",
    "svc = SVC(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    probability=False,\n",
    "    cache_size=1500,\n",
    "    max_iter=100000\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-2, 1e3),\n",
    "    'gamma': loguniform(1e-4, 1e1),\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "halving_search = HalvingRandomSearchCV(\n",
    "    estimator=svc,\n",
    "    param_distributions=param_dist,\n",
    "    n_candidates=28,\n",
    "    factor=3,\n",
    "    resource='n_samples',\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d2ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Training WITHOUT SAMPLING =================\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 12\n",
      "max_resources_: 47678\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 28\n",
      "n_resources: 12\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 10\n",
      "n_resources: 36\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 108\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 324\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "AUC Without Sampling: 0.8268994570996278\n",
      "Saved: submission_svm_nosample.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  MODEL 1: TRAIN WITHOUT ANY SAMPLING\n",
    "\n",
    "print(\"\\n================= Training WITHOUT SAMPLING =================\")\n",
    "halving_search.fit(X_train_processed, y_train)\n",
    "\n",
    "best_model_no_sample = halving_search.best_estimator_\n",
    "\n",
    "val_scores = best_model_no_sample.decision_function(X_val_processed)\n",
    "auc_no_sample = roc_auc_score(y_test_val, val_scores)\n",
    "\n",
    "print(\"AUC Without Sampling:\", auc_no_sample)\n",
    "\n",
    "# Final training\n",
    "X_full_proc = np.vstack([X_train_processed, X_val_processed])\n",
    "y_full = np.concatenate([y_train.values, y_test_val.values])\n",
    "\n",
    "best_model_no_sample.fit(X_full_proc, y_full)\n",
    "\n",
    "# Save CSV\n",
    "df_pred = pd.DataFrame({\n",
    "    'founder_id': test['founder_id'],\n",
    "    'retention_status': np.where(\n",
    "        best_model_no_sample.predict(X_test_processed) == 1, 'Stayed', 'Left'\n",
    "    )\n",
    "})\n",
    "df_pred.to_csv(\"submission_svm_nosample.csv\", index=False)\n",
    "print(\"Saved: submission_svm_nosample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac80ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Training WITH SMOTE =================\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 12\n",
      "max_resources_: 50016\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 28\n",
      "n_resources: 12\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 10\n",
      "n_resources: 36\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 108\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 324\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "AUC With SMOTE: 0.8221561901885117\n",
      "Saved: submission_svm_smote.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  MODEL 2: TRAIN WITH SMOTE \n",
    "\n",
    "print(\"\\n================= Training WITH SMOTE =================\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_sm, y_sm = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "halving_search.fit(X_sm, y_sm)\n",
    "best_model_smote = halving_search.best_estimator_\n",
    "\n",
    "val_scores_smote = best_model_smote.decision_function(X_val_processed)\n",
    "auc_smote = roc_auc_score(y_test_val, val_scores_smote)\n",
    "\n",
    "print(\"AUC With SMOTE:\", auc_smote)\n",
    "\n",
    "best_model_smote.fit(X_full_proc, y_full)\n",
    "\n",
    "df_pred2 = pd.DataFrame({\n",
    "    'founder_id': test['founder_id'],\n",
    "    'retention_status': np.where(\n",
    "        best_model_smote.predict(X_test_processed) == 1, 'Stayed', 'Left'\n",
    "    )\n",
    "})\n",
    "df_pred2.to_csv(\"submission_svm_smote.csv\", index=False)\n",
    "print(\"Saved: submission_svm_smote.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e235aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FINAL SUMMARY ================\n",
      "AUC (No Sampling): 0.8269\n",
      "AUC (SMOTE): 0.8222\n",
      "Generated:\n",
      "- submission_svm_nosample.csv\n",
      "- submission_svm_smote.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n================ FINAL SUMMARY ================\")\n",
    "print(f\"AUC (No Sampling): {auc_no_sample:.4f}\")\n",
    "print(f\"AUC (SMOTE): {auc_smote:.4f}\")\n",
    "print(\"Generated:\")\n",
    "print(\"- submission_svm_nosample.csv\")\n",
    "print(\"- submission_svm_smote.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
